


import plotly.express as px
import plotly.graph_objects as go
import pandas as pd
import numpy as np
from datetime import timedelta, datetime
from ipywidgets import interact, widgets
import matplotlib.pyplot as plt
import matplotlib.colors as mcolors
from matplotlib.colors import ListedColormap
import matplotlib.cm as cm
import seaborn as sns
import os
import folium
from folium.plugins import HeatMap
from folium.plugins import HeatMapWithTime
import datetime
from sklearn.cluster import KMeans
from geopy.distance import geodesic 
import warnings
from collections import defaultdict
import requests
import uuid
import random


df = pd.read_csv("cluster_metrics.csv")
# Redondear las coordenadas a 3 decimales
df['Lat_Rounded'] = df['Centroide_Lat'].round(3)
df['Lon_Rounded'] = df['Centroide_Lon'].round(3)

# Eliminar filas duplicadas basadas en las coordenadas redondeadas
unique_coords = df[['Lat_Rounded', 'Lon_Rounded']].drop_duplicates()

# Crear un diccionario para almacenar las altitudes
altitudes = {}

# Iterar sobre las coordenadas únicas y hacer solicitudes a la API
for _, row in unique_coords.iterrows():
    lat = row['Lat_Rounded']
    lon = row['Lon_Rounded']
    url = f'https://api.open-meteo.com/v1/elevation?latitude={lat}&longitude={lon}'
    response = requests.get(url)
    if response.status_code == 200:
        data = response.json()
        elevation = data.get('elevation', None)
        if elevation is not None:
            # Convertir la altitud a cadena y eliminar corchetes si existen
            elevation_str = str(elevation).replace('[', '').replace(']', '')
            altitudes[(lat, lon)] = elevation_str
        else:
            altitudes[(lat, lon)] = None
    else:
        altitudes[(lat, lon)] = None

# Crear una nueva columna en el DataFrame original para las altitudes
df['Altitud'] = df.apply(lambda x: altitudes.get((x['Lat_Rounded'], x['Lon_Rounded'])), axis=1)

# Eliminar las columnas temporales
df.drop(columns=['Lat_Rounded', 'Lon_Rounded'], inplace=True)
df





import pandas as pd

# Verificar los tipos de datos
print(df.dtypes)

# Parámetros del patinete
consumo_base = 13.5  # Consumo base en Wh/km
k_inclinacion = 0.1  # Factor de ajuste por inclinación (aumenta el consumo por cada 1% de inclinación)

# Convertir a numérico
df['Altitud'] = pd.to_numeric(df['Altitud'], errors='coerce')
df['Distancia_Media_km'] = pd.to_numeric(df['Distancia_Media_km'], errors='coerce')

# Manejar valores nulos
df = df.dropna(subset=['Altitud', 'Distancia_Media_km'])

# Función para calcular el consumo energético de cada viaje
def calcular_consumo(row):
    distancia_km = row['Distancia_Media_km'] / 1000  # Convertimos de metros a kilómetros
    consumo_ajustado = consumo_base * (1 + k_inclinacion * row['Altitud'] / 100)
    consumo_energia = consumo_ajustado * distancia_km  # en Wh
    return consumo_energia

# Calcular el consumo de energía
df['consumo_energia'] = df.apply(calcular_consumo, axis=1)

# Mostrar resultados
print(df[['Cluster_ID', 'Distancia_Media_km', 'Altitud', 'consumo_energia']].head())






df = pd.read_csv("df_with_clusters.csv")

# Definir la capacidad de la batería y el tiempo de recarga
capacidad_bateria = 576  # en Wh
tiempo_recarga = 7  # en horas

# Calcular la potencia demandada por cada patinete (en W)
potencia_demandada_por_patinete = capacidad_bateria / tiempo_recarga  # en W

# Función para calcular la energía demandada por cada estación en un intervalo de tiempo
def calcular_demanda_energia(df, intervalo='H'):
    # Agrupar los datos por cluster de origen (estaciones) y por hora
    df['tsO'] = pd.to_datetime(df['tsO'])  # Asegurarse de que 'tsO' es tipo datetime
    df['hora'] = df['tsO'].dt.floor(intervalo)  # Redondear la hora a intervalos

    # Contar cuántos patinetes recargan en cada intervalo de tiempo y estación (clúster de origen)
    demanda_por_intervalo = df.groupby(['clusterO', 'hora']).size().reset_index(name='num_patinetes')

    # Calcular la demanda de energía en Wh por cada intervalo de tiempo
    demanda_por_intervalo['energia_demandada'] = demanda_por_intervalo['num_patinetes'] * potencia_demandada_por_patinete

    return demanda_por_intervalo

# Llamar a la función y obtener el resultado
demanda_energia = calcular_demanda_energia(df)
print(demanda_energia)






df = pd.read_csv("cluster_metrics2.csv")
# Supongamos que tu DataFrame se llama df y tiene las columnas 'Centroide_Lat' y 'Centroide_Lon'
# Redondear las coordenadas a 3 decimales
df['Lat_Rounded'] = df['Centroide_Lat'].round(3)
df['Lon_Rounded'] = df['Centroide_Lon'].round(3)

# Eliminar filas duplicadas basadas en las coordenadas redondeadas
unique_coords = df[['Lat_Rounded', 'Lon_Rounded']].drop_duplicates()

# Crear un diccionario para almacenar las altitudes
altitudes = {}

# Iterar sobre las coordenadas únicas y hacer solicitudes a la API
for _, row in unique_coords.iterrows():
    lat = row['Lat_Rounded']
    lon = row['Lon_Rounded']
    url = f'https://api.open-meteo.com/v1/elevation?latitude={lat}&longitude={lon}'
    response = requests.get(url)
    if response.status_code == 200:
        data = response.json()
        elevation = data.get('elevation', None)
        if elevation is not None:
            # Convertir la altitud a cadena y eliminar corchetes si existen
            elevation_str = str(elevation).replace('[', '').replace(']', '')
            altitudes[(lat, lon)] = elevation_str
        else:
            altitudes[(lat, lon)] = None
    else:
        altitudes[(lat, lon)] = None

# Crear una nueva columna en el DataFrame original para las altitudes
df['Altitud'] = df.apply(lambda x: altitudes.get((x['Lat_Rounded'], x['Lon_Rounded'])), axis=1)

# Eliminar las columnas temporales
df.drop(columns=['Lat_Rounded', 'Lon_Rounded'], inplace=True)
df





import pandas as pd

# Verificar los tipos de datos
print(df.dtypes)

# Convertir a numérico
df['Altitud'] = pd.to_numeric(df['Altitud'], errors='coerce')
df['Distancia_Media_km'] = pd.to_numeric(df['Distancia_Media_km'], errors='coerce')

# Manejar valores nulos
df = df.dropna(subset=['Altitud', 'Distancia_Media_km'])

# Función para calcular el consumo energético de cada viaje
def calcular_consumo(row):
    distancia_km = row['Distancia_Media_km'] / 1000  # Convertimos de metros a kilómetros
    consumo_ajustado = consumo_base * (1 + k_inclinacion * row['Altitud'] / 100)
    consumo_energia = consumo_ajustado * distancia_km  # en Wh
    return consumo_energia

# Calcular el consumo de energía
df['consumo_energia'] = df.apply(calcular_consumo, axis=1)

# Mostrar resultados
print(df[['Cluster_ID', 'Distancia_Media_km', 'Altitud', 'consumo_energia']].head())






df = pd.read_csv("df_with_clusters2.csv")

# Definir la capacidad de la batería y el tiempo de recarga
capacidad_bateria = 576  # en Wh
tiempo_recarga = 7  # en horas

# Calcular la potencia demandada por cada patinete (en W)
potencia_demandada_por_patinete = capacidad_bateria / tiempo_recarga  # en W

# Función para calcular la energía demandada por cada estación en un intervalo de tiempo
def calcular_demanda_energia(df, intervalo='H'):
    # Agrupar los datos por cluster de origen (estaciones) y por hora
    df['tsO'] = pd.to_datetime(df['tsO'])  # Asegurarse de que 'tsO' es tipo datetime
    df['hora'] = df['tsO'].dt.floor(intervalo)  # Redondear la hora a intervalos

    # Contar cuántos patinetes recargan en cada intervalo de tiempo y estación (clúster de origen)
    demanda_por_intervalo = df.groupby(['clusterO', 'hora']).size().reset_index(name='num_patinetes')

    # Calcular la demanda de energía en Wh por cada intervalo de tiempo
    demanda_por_intervalo['energia_demandada'] = demanda_por_intervalo['num_patinetes'] * potencia_demandada_por_patinete

    return demanda_por_intervalo

# Llamar a la función y obtener el resultado
demanda_energia = calcular_demanda_energia(df)
print(demanda_energia)



import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

# Definir la capacidad de la batería y el tiempo de recarga
capacidad_bateria = 576  # en Wh
tiempo_recarga = 7  # en horas

# Calcular la potencia demandada por cada patinete (en W)
potencia_demandada_por_patinete = capacidad_bateria / tiempo_recarga  # en W

# Función para calcular la energía demandada por cada estación en cada hora
def calcular_demanda_energia(df, intervalo='H'):
    # Convertir la columna 'tsO' a datetime
    df['tsO'] = pd.to_datetime(df['tsO'])  # Asegurarse de que 'tsO' es tipo datetime
    df['hora'] = df['tsO'].dt.hour  # Extraer solo la hora del día

    # Contar cuántos patinetes recargan en cada hora
    demanda_por_intervalo = df.groupby(['hora']).size().reset_index(name='num_patinetes')

    # Calcular la demanda de energía en Wh por cada intervalo de hora
    demanda_por_intervalo['energia_demandada'] = demanda_por_intervalo['num_patinetes'] * potencia_demandada_por_patinete

    return demanda_por_intervalo



# Calcular la demanda de energía por hora
demanda_energia = calcular_demanda_energia(df)

# Graficar la demanda de energía por hora del día
plt.figure(figsize=(10, 6))
plt.plot(demanda_energia['hora'], demanda_energia['energia_demandada'], marker='o', linestyle='-', color='b')

plt.xlabel('Hora del día')
plt.ylabel('Energía demandada (Wh)')
plt.title('Demanda de energía por hora del día en las estaciones de recarga')
plt.grid(True)
plt.xticks(np.arange(0, 24, 1))  # Marcar cada hora
plt.show()



import pandas as pd
import numpy as np
import plotly.graph_objects as go

# Definir la capacidad de la batería y el tiempo de recarga
capacidad_bateria = 576  # en Wh
tiempo_recarga = 7  # en horas

# Calcular la potencia demandada por cada patinete (en W)
potencia_demandada_por_patinete = capacidad_bateria / tiempo_recarga  # en W

# Función para calcular la demanda de energía por estación y por hora
def calcular_demanda_energia(df, intervalo='H'):
    # Convertir la columna 'tsO' a datetime
    df['tsO'] = pd.to_datetime(df['tsO'])  # Asegurarse de que 'tsO' es tipo datetime
    df['hora'] = df['tsO'].dt.hour  # Extraer solo la hora del día

    # Contar cuántos patinetes recargan en cada estación y hora
    demanda_por_intervalo = df.groupby(['hora', 'clusterO']).size().reset_index(name='num_patinetes')

    # Calcular la demanda de energía en Wh por cada intervalo de hora y estación
    demanda_por_intervalo['energia_demandada'] = demanda_por_intervalo['num_patinetes'] * potencia_demandada_por_patinete

    return demanda_por_intervalo


# Calcular la demanda de energía por hora y por estación
demanda_energia = calcular_demanda_energia(df)

# Crear un gráfico interactivo de la demanda de energía por estación y por hora
fig = go.Figure()

# Usamos un gráfico de líneas para cada estación (grupo 'clusterO')
for estacion in demanda_energia['clusterO'].unique():
    estacion_data = demanda_energia[demanda_energia['clusterO'] == estacion]
    fig.add_trace(go.Scatter(
        x=estacion_data['hora'],
        y=estacion_data['energia_demandada'],
        mode='lines+markers',
        name=f'Cluster {estacion}',
        hovertemplate='Hora: %{x}<br>Demanda Energía: %{y} Wh'
    ))

# Añadir título y etiquetas
fig.update_layout(
    title='Demanda de Energía por Hora y Estación de Recarga',
    xaxis_title='Hora del Día',
    yaxis_title='Energía Demandada (Wh)',
    template='plotly_dark',  # Opcional: Puedes cambiar el tema a "plotly", "ggplot2", "seaborn", etc.
    showlegend=True
)

# Mostrar el gráfico
fig.show()



import pandas as pd
import numpy as np
import plotly.graph_objects as go

# Definir la capacidad de la batería y el tiempo de recarga
capacidad_bateria = 576  # en Wh
tiempo_recarga = 7  # en horas

# Calcular la potencia demandada por cada patinete (en W)
potencia_demandada_por_patinete = capacidad_bateria / tiempo_recarga  # en W

# Función para calcular la demanda de energía por estación y por hora
def calcular_demanda_energia(df):
    # Convertir la columna 'tsO' a datetime
    df['tsO'] = pd.to_datetime(df['tsO'])  # Asegurarse de que 'tsO' es tipo datetime
    df['hora'] = df['tsO'].dt.hour  # Extraer solo la hora del día

    # Contar cuántos patinetes recargan en cada estación y hora
    demanda_por_intervalo = df.groupby(['hora', 'clusterO']).size().reset_index(name='num_patinetes')

    # Calcular la demanda de energía en Wh por cada intervalo de hora y estación
    demanda_por_intervalo['energia_demandada'] = demanda_por_intervalo['num_patinetes'] * potencia_demandada_por_patinete

    return demanda_por_intervalo


# Calcular la demanda de energía por hora y por estación
demanda_energia = calcular_demanda_energia(df)

# Crear un gráfico interactivo para cada cluster
for estacion in demanda_energia['clusterO'].unique():
    estacion_data = demanda_energia[demanda_energia['clusterO'] == estacion]
    
    # Crear el gráfico para cada estación
    fig = go.Figure()

    fig.add_trace(go.Scatter(
        x=estacion_data['hora'],
        y=estacion_data['energia_demandada'],
        mode='lines+markers',
        name=f'Cluster {estacion}',
        hovertemplate='Hora: %{x}<br>Demanda Energía: %{y} Wh'
    ))

    # Añadir título y etiquetas
    fig.update_layout(
        title=f'Demanda de Energía por Hora en Estación {estacion}',
        xaxis_title='Hora del Día',
        yaxis_title='Energía Demandada (Wh)',
        template='plotly_dark',  # Opcional: Puedes cambiar el tema a "plotly", "ggplot2", "seaborn", etc.
        showlegend=True
    )

    # Mostrar el gráfico
    fig.show()






# Leer el DataFrame desde el archivo CSV
df = pd.read_csv("cluster_metrics.csv")

# Función para obtener la distancia desde OSRM
def get_route_distance(lat1, lon1, lat2, lon2, osrm_url="http://router.project-osrm.org"):
    try:
        # Validación de entrada
        if not all(map(lambda x: isinstance(x, (float, int)), [lat1, lon1, lat2, lon2])):
            raise ValueError("Las coordenadas deben ser números (float o int).")
        
        # Construcción de la URL de OSRM
        route_url = f"{osrm_url}/route/v1/bike/{lon1},{lat1};{lon2},{lat2}?overview=full&geometries=geojson"
        
        # Llamada a la API
        response = requests.get(route_url)
        
        if response.status_code == 200:
            result = response.json()
            # Extraer distancia (en metros, convertir a km)
            distance = result['routes'][0]['distance'] / 1000  # en km
            return distance
        else:
            print(f"Error en la API OSRM: {response.status_code}")
            return None
    except Exception as e:
        print(f"Error al calcular la ruta: {e}")
        return None

# Obtener distancias y desniveles para todas las combinaciones de origen-destino
routes = []
for i, row1 in df.iterrows():
    for j, row2 in df.iterrows():
        if i != j:  # Evitar calcular rutas entre el mismo punto
            distance = get_route_distance(
                row1["Centroide_Lat"], row1["Centroide_Lon"], 
                row2["Centroide_Lat"], row2["Centroide_Lon"]
            )
            desnivel = row2["Altitud"] - row1["Altitud"]  # Calcular el desnivel
            routes.append({
                "Origen": row1["Cluster_ID"],
                "Destino": row2["Cluster_ID"],
                "Distancia_km": distance,
                "Desnivel": desnivel
            })

# Convertir resultados a DataFrame
routes_df = pd.DataFrame(routes)

# Mostrar el DataFrame resultante
routes_df


# Factor de impacto del desnivel (puedes ajustar este valor según las pruebas o especificaciones)
k = 0.1  # Incremento de Wh por metro de desnivel positivo

# Función para calcular el consumo
def calcular_consumo(distancia_km, desnivel):
    # Consumo base por distancia
    consumo = distancia_km * 13.5
    
    # Ajuste por desnivel
    if desnivel > 0:  # Subida
        consumo += k * desnivel
    elif desnivel < 0:  # Bajada
        consumo += k * desnivel  # Bajadas conservan el impacto, podría ajustarse si hay recuperación de energía
    return max(consumo, 0)  # El consumo no puede ser negativo

# Aplicar la función a cada fila del DataFrame
routes_df["Consumo_Wh"] = routes_df.apply(
    lambda row: calcular_consumo(row["Distancia_km"], row["Desnivel"]), axis=1
)
routes_df.to_csv('rutas.csv', index=False)
# Mostrar el DataFrame actualizado
routes_df



df_viajes = pd.read_csv('df_with_clusters.csv')
df_energia = pd.read_csv('rutas.csv')

# Convertir las columnas relevantes a tipos compatibles para el merge
df_energia['Origen'] = df_energia['Origen'].astype(int)
df_energia['Destino'] = df_energia['Destino'].astype(int)

# Realizar el merge para asociar la energía consumida según el origen y destino
df_viajes = df_viajes.merge(
    df_energia[['Origen', 'Destino', 'Consumo_Wh']],
    left_on=['clusterO', 'clusterD'],
    right_on=['Origen', 'Destino'],
    how='left'
)

# Calcular la energía para los casos donde origen y destino son iguales
df_viajes['Consumo_Wh'] = df_viajes.apply(
    lambda row: (row['dis']/1000) * 13.5 if row['clusterO'] == row['clusterD'] else row['Consumo_Wh'],
    axis=1
)
# Eliminar las columnas auxiliares si ya no son necesarias
df_viajes.drop(columns=['Origen', 'Destino'], inplace=True, errors='ignore')
df_viajes['Consumo_Wh'] = df_viajes['Consumo_Wh'].round(2)

df_viajes.to_csv('df_with_energy.csv')
df_viajes





# Leer los archivos CSV
df = pd.read_csv('df_with_energy.csv')
df['tsD'] = pd.to_datetime(df_energy['tsD'], format='%d/%m/%Y %H:%M:%S', dayfirst=True)
df['tsO'] = pd.to_datetime(df_energy['tsO'], format='%Y-%m-%d %H:%M:%S', dayfirst=False)
# Crear DataFrame combinado
df_tsO_clusterO = df[['tsO', 'clusterO','Consumo_Wh']].copy()
df_tsO_clusterO['Consumo_Wh'] = 0
df_tsD_clusterD = df[['tsD', 'clusterD','Consumo_Wh']].copy()

df_tsO_clusterO['tipo'] = 'origen'
df_tsD_clusterD['tipo'] = 'destino'

df_tsO_clusterO.rename(columns={'tsO': 'ts', 'clusterO': 'nodo'}, inplace=True)
df_tsD_clusterD.rename(columns={'tsD': 'ts', 'clusterD': 'nodo'}, inplace=True)

df_combinado = pd.concat([df_tsO_clusterO, df_tsD_clusterD], ignore_index=True)
df_combinado.sort_values(by='ts', inplace=True)
df_combinado.reset_index(drop=True, inplace=True)
df_combinado.tail()


# Asegúrate de que la columna de tiempo está en formato datetime
df_combinado['ts'] = pd.to_datetime(df_combinado['ts'])

# Crear una columna de fecha (sin horas) para el consumo medio diario
df_combinado['fecha'] = df_combinado['ts'].dt.date

# Consumo medio diario
consumo_medio_diario = df_combinado.groupby('fecha')['Consumo_Wh'].sum().mean()
print("Consumo medio diario:", consumo_medio_diario, 'Wh')


# Asegúrate de que la columna 'ts' esté en formato datetime
df_combinado['ts'] = pd.to_datetime(df_combinado['ts'])

# Crear una columna 'fecha' para simplificar el agrupamiento diario
df_combinado['fecha'] = df_combinado['ts'].dt.date

# Crear una columna 'dia_semana' para identificar el día de la semana (0 = lunes, ..., 6 = domingo)
df_combinado['dia_semana'] = df_combinado['ts'].dt.dayofweek

# Agrupar por 'fecha' y sumar el consumo para cada día
consumo_diario = df_combinado.groupby('fecha')['Consumo_Wh'].sum().reset_index()

# Añadir la columna 'dia_semana' para saber a qué día pertenece cada fecha
consumo_diario['dia_semana'] = pd.to_datetime(consumo_diario['fecha']).dt.dayofweek

# Crear un diccionario para almacenar el consumo medio por cada día de la semana
consumo_medio_dia_semana = {}

# Iterar sobre cada día de la semana (0 = lunes, ..., 6 = domingo)
for dia in range(7):
    # Filtrar los días específicos del día de la semana actual
    consumo_dia_especifico = consumo_diario[consumo_diario['dia_semana'] == dia]['Consumo_Wh']
    
    # Calcular el consumo medio para ese día de la semana
    consumo_medio_dia_semana[dia] = consumo_dia_especifico.mean()

# Convertir los índices a nombres de días para una mejor presentación
dias_semana_nombres = ['Lunes', 'Martes', 'Miércoles', 'Jueves', 'Viernes', 'Sábado', 'Domingo']
consumo_medio_dia_semana_named = {dias_semana_nombres[dia]: consumo_medio_dia_semana[dia] for dia in consumo_medio_dia_semana}

# Imprimir los resultados
print("Consumo medio por día de la semana:")
for dia, consumo in consumo_medio_dia_semana_named.items():
    print(f"{dia}: {consumo:.2f} Wh")


# Datos para el gráfico de barras
dias = list(consumo_medio_dia_semana_named.keys())
consumos = list(consumo_medio_dia_semana_named.values())

# Crear el gráfico de barras
fig = go.Figure(data=[
    go.Bar(x=dias, y=consumos, text=[f"{c:.2f} Wh" for c in consumos], textposition='auto')
])

# Añadir títulos y etiquetas
fig.update_layout(
    title='Consumo Medio por Día de la Semana',
    xaxis_title='Día de la Semana',
    yaxis_title='Consumo Medio (Wh)',
    template='plotly_white'
)

# Mostrar el gráfico
fig.show()


# Asegúrate de que la columna 'ts' esté en formato datetime
df_combinado['ts'] = pd.to_datetime(df_combinado['ts'])

patinetes = pd.read_csv('dimensiones_mes1.csv')

# Agrupar por 'fecha' y calcular el consumo total
consumo_por_dia = df_combinado.groupby(['fecha'])['Consumo_Wh'].sum().reset_index()

# Obtener el número total de patinetes para calcular el consumo promedio por patinete
total_patinetes = patinetes['patinetes_iniciales'].sum()

# Calcular el consumo medio por patinete y día dividiendo la columna 'Consumo_Wh' por el número total de patinetes
consumo_por_dia['Consumo_medio_por_patinete'] = consumo_por_dia['Consumo_Wh'] / total_patinetes

# Mostrar las primeras filas del resultado
consumo_por_dia




# Crear el gráfico de líneas con Plotly para el consumo medio por patinete y día
fig = px.line(
    consumo_por_dia, 
    x='fecha', 
    y='Consumo_medio_por_patinete', 
    title='Consumo Medio por Patinete y Día del Mes',
    labels={'fecha': 'Fecha', 'Consumo_medio_por_patinete': 'Consumo Medio por Patinete (Wh)'}
)

# Mostrar el gráfico
fig.show()


# Inicializar las estaciones y las variables
num_estaciones = 40
inicio_mes = dt(2021, 2, 1)
fin_mes = dt(2021, 2, 28)

# Crear una nueva columna para almacenar los patinetes necesarios cada día
consumo_por_dia['patinetes_necesarios'] = 0

# Recorrer cada día del mes y hacer la simulación para cada día
for dia in range((fin_mes - inicio_mes).days + 1):
    # Inicializar las estaciones para cada día (reiniciar a 1 los parámetros iniciales)
    estaciones = {
        i: {
            "patinetes_iniciales": 1,
            "patinetes_disponibles": 1,  # Inicialmente un patinete
            "slots": 1  # Inicialmente un slot
        }
        for i in range(num_estaciones)
    }
    
    # Definir la fecha actual y la siguiente para filtrar los datos
    fecha_actual = inicio_mes + timedelta(days=dia)
    siguiente_dia = fecha_actual + timedelta(days=1)

    # Filtrar datos del día actual
    df_dia = df_combinado[(df_combinado['ts'] >= fecha_actual) & (df_combinado['ts'] < siguiente_dia)]

    # Simular los eventos del día
    for _, evento in df_dia.iterrows():
        nodo = evento['nodo']
        tipo = evento['tipo']

        if tipo == 'origen':
            if estaciones[nodo]['patinetes_disponibles'] > 0:
                estaciones[nodo]['patinetes_disponibles'] -= 1
            else:
                estaciones[nodo]['patinetes_iniciales'] += 1
                estaciones[nodo]['patinetes_disponibles'] = 0
                if estaciones[nodo]['patinetes_iniciales'] > estaciones[nodo]['slots']:
                    estaciones[nodo]['slots'] += 1

        elif tipo == 'destino':
            if estaciones[nodo]['patinetes_disponibles'] < estaciones[nodo]['slots']:
                estaciones[nodo]['patinetes_disponibles'] += 1
            else:
                estaciones[nodo]['slots'] += 1
                estaciones[nodo]['patinetes_disponibles'] += 1

    # Calcular el total de patinetes necesarios al final del día
    patinetes_necesarios_dia = sum(estacion['patinetes_iniciales'] for estacion in estaciones.values())

    # Actualizar el DataFrame con el número de patinetes necesarios para ese día
    consumo_por_dia.loc[consumo_por_dia['fecha'] == fecha_actual.date(), 'patinetes_necesarios'] = patinetes_necesarios_dia

# Mostrar las primeras filas del resultado actualizado
consumo_por_dia





# Leer el archivo CSV principal
df = pd.read_csv('df_with_energy.csv')

# Convertir las columnas de fechas a formato datetime
df['tsD'] = pd.to_datetime(df['tsD'], format='%d/%m/%Y %H:%M:%S', dayfirst=True, errors='coerce')
df['tsO'] = pd.to_datetime(df['tsO'], format='%Y-%m-%d %H:%M:%S', errors='coerce')

# Verificar si hay valores NaT en las columnas de fechas
if df['tsD'].isna().any() or df['tsO'].isna().any():
    print("Advertencia: Algunos valores de fecha no se pudieron convertir correctamente.")

# Crear DataFrames separados para origen y destino
df_tsO_clusterO = df[['tsO', 'clusterO', 'Consumo_Wh']].copy()
df_tsO_clusterO['Consumo_Wh'] = 0  # Inicializar a 0 el consumo para los puntos de origen
df_tsD_clusterD = df[['tsD', 'clusterD', 'Consumo_Wh']].copy()

df_tsO_clusterO['tipo'] = 'origen'
df_tsD_clusterD['tipo'] = 'destino'

# Renombrar columnas para unificar los DataFrames
df_tsO_clusterO.rename(columns={'tsO': 'ts', 'clusterO': 'nodo'}, inplace=True)
df_tsD_clusterD.rename(columns={'tsD': 'ts', 'clusterD': 'nodo'}, inplace=True)

# Concatenar ambos DataFrames
df_combinado = pd.concat([df_tsO_clusterO, df_tsD_clusterD], ignore_index=True)

# Ordenar por timestamp
df_combinado.sort_values(by='ts', inplace=True)
df_combinado.reset_index(drop=True, inplace=True)

# Filtrar por el 20 de febrero de 2021
df_combinado = df_combinado[df_combinado['ts'].dt.date == pd.Timestamp('2021-02-20').date()]

# Filtrar por viajes de destino
df_destino = df_combinado[df_combinado['tipo'] == 'destino'].copy()

# Extraer la hora de la columna 'ts'
df_destino['hora'] = df_destino['ts'].dt.hour

# Agrupar por nodo y hora, sumando los consumos
consumo_hora_estacion = df_destino.groupby(['nodo', 'hora'])['Consumo_Wh'].sum().unstack(fill_value=0)

# Leer el archivo de estaciones
estaciones = pd.read_csv('dimensiones_mes1.csv')

# Asegurar que todas las estaciones están representadas en la matriz de consumo
estaciones_ids = estaciones['estacion']
consumo_hora_estacion = consumo_hora_estacion.reindex(estaciones_ids, fill_value=0.00).sort_index()

# Asegurarse de incluir las 24 horas (incluso si no hay datos para algunas)
horas = list(range(24))
consumo_hora_estacion = consumo_hora_estacion.reindex(columns=horas, fill_value=0.00)

# Resultado
consumo_hora_estacion





import pandas as pd

# Leer el archivo CSV principal
df = pd.read_csv('df_with_energy.csv')

# Convertir las columnas de fechas a formato datetime
df['tsD'] = pd.to_datetime(df['tsD'], format='%d/%m/%Y %H:%M:%S', dayfirst=True, errors='coerce')
df['tsO'] = pd.to_datetime(df['tsO'], format='%Y-%m-%d %H:%M:%S', errors='coerce')

# Verificar si hay valores NaT en las columnas de fechas
if df['tsD'].isna().any() or df['tsO'].isna().any():
    print("Advertencia: Algunos valores de fecha no se pudieron convertir correctamente.")

# Crear DataFrames separados para origen y destino
df_tsO_clusterO = df[['tsO', 'clusterO', 'Consumo_Wh']].copy()
df_tsO_clusterO['Consumo_Wh'] = 0  # Inicializar a 0 el consumo para los puntos de origen
df_tsD_clusterD = df[['tsD', 'clusterD', 'Consumo_Wh']].copy()

df_tsO_clusterO['tipo'] = 'origen'
df_tsD_clusterD['tipo'] = 'destino'

# Renombrar columnas para unificar los DataFrames
df_tsO_clusterO.rename(columns={'tsO': 'ts', 'clusterO': 'nodo'}, inplace=True)
df_tsD_clusterD.rename(columns={'tsD': 'ts', 'clusterD': 'nodo'}, inplace=True)

# Concatenar ambos DataFrames
df_combinado = pd.concat([df_tsO_clusterO, df_tsD_clusterD], ignore_index=True)

# Ordenar por timestamp
df_combinado.sort_values(by='ts', inplace=True)
df_combinado.reset_index(drop=True, inplace=True)

# Filtrar solo los registros dentro del mes de febrero de 2021
df_combinado = df_combinado[
    (df_combinado['ts'].dt.month == 2) & (df_combinado['ts'].dt.year == 2021)
]

# Filtrar por viajes de destino
df_destino = df_combinado[df_combinado['tipo'] == 'destino'].copy()

# Extraer la fecha y hora de la columna 'ts'
df_destino['fecha'] = df_destino['ts'].dt.date
df_destino['hora'] = df_destino['ts'].dt.hour

# Agrupar por nodo, fecha y hora, sumando los consumos
consumo_hora_estacion = df_destino.groupby(['nodo', 'fecha', 'hora'])['Consumo_Wh'].sum()

# Leer el archivo de estaciones
estaciones = pd.read_csv('dimensiones_mes1.csv')

# Asegurar que todas las estaciones están representadas
estaciones_ids = estaciones['estacion']
horas = list(range(24))

# Crear un DataFrame con todos los días de febrero, horas y estaciones
fechas_febrero = pd.date_range(start='2021-02-01', end='2021-02-28', freq='D')
multi_index = pd.MultiIndex.from_product([estaciones_ids, fechas_febrero, horas],
                                         names=['nodo', 'fecha', 'hora'])
consumo_hora_estacion = consumo_hora_estacion.reindex(multi_index, fill_value=0.00)

# Convertir el resultado a un DataFrame
consumo_hora_estacion = consumo_hora_estacion.reset_index()

# Resultado final
consumo_hora_estacion






import pandas as pd

# Leer el archivo CSV principal
df = pd.read_csv('df_with_energy.csv')

# Convertir las columnas de fechas a formato datetime
df['tsD'] = pd.to_datetime(df['tsD'], format='%d/%m/%Y %H:%M:%S', dayfirst=True, errors='coerce')
df['tsO'] = pd.to_datetime(df['tsO'], format='%Y-%m-%d %H:%M:%S', errors='coerce')

# Verificar si hay valores NaT en las columnas de fechas
if df['tsD'].isna().any() or df['tsO'].isna().any():
    print("Advertencia: Algunos valores de fecha no se pudieron convertir correctamente.")

# Crear DataFrames separados para origen y destino
df_tsO_clusterO = df[['tsO', 'clusterO', 'Consumo_Wh']].copy()
df_tsO_clusterO['Consumo_Wh'] = 0  # Inicializar a 0 el consumo para los puntos de origen
df_tsD_clusterD = df[['tsD', 'clusterD', 'Consumo_Wh']].copy()

df_tsO_clusterO['tipo'] = 'origen'
df_tsD_clusterD['tipo'] = 'destino'

# Renombrar columnas para unificar los DataFrames
df_tsO_clusterO.rename(columns={'tsO': 'ts', 'clusterO': 'nodo'}, inplace=True)
df_tsD_clusterD.rename(columns={'tsD': 'ts', 'clusterD': 'nodo'}, inplace=True)

# Concatenar ambos DataFrames
df_combinado = pd.concat([df_tsO_clusterO, df_tsD_clusterD], ignore_index=True)

# Ordenar por timestamp
df_combinado.sort_values(by='ts', inplace=True)
df_combinado.reset_index(drop=True, inplace=True)

# Filtrar datos para el mes deseado (por ejemplo, febrero de 2021)
df_combinado = df_combinado[(df_combinado['ts'].dt.year == 2021) & (df_combinado['ts'].dt.month == 2)]

# Filtrar por viajes de destino
df_destino = df_combinado[df_combinado['tipo'] == 'destino'].copy()

# Extraer la hora de la columna 'ts'
df_destino['hora'] = df_destino['ts'].dt.hour

# Agrupar por nodo y hora, calculando la media de los consumos
consumo_hora_estacion = df_destino.groupby(['nodo', 'hora'])['Consumo_Wh'].mean().unstack(fill_value=0)

# Leer el archivo de estaciones
estaciones = pd.read_csv('dimensiones_mes1.csv')

# Asegurar que todas las estaciones están representadas en la matriz de consumo
estaciones_ids = estaciones['estacion']
consumo_hora_estacion = consumo_hora_estacion.reindex(estaciones_ids, fill_value=0.00).sort_index()

# Asegurarse de incluir las 24 horas (incluso si no hay datos para algunas)
horas = list(range(24))
consumo_hora_estacion = consumo_hora_estacion.reindex(columns=horas, fill_value=0.00)

# Resultado
consumo_hora_estacion



# Guardar el resultado en un archivo CSV
output_file = 'consumo_hora_estacion.csv'
consumo_hora_estacion.to_csv(output_file, index=True)


# Seleccionar una estación al azar
estacion_aleatoria = random.choice(consumo_hora_estacion.index)

# Preparar los datos para el gráfico
df_grafico = consumo_hora_estacion.loc[estacion_aleatoria].reset_index()
df_grafico.columns = ['Hora', 'Consumo_Wh']

# Crear el gráfico de barras
fig = px.bar(
    df_grafico,
    x='Hora',
    y='Consumo_Wh',
    title=f'Consumo promedio por hora - Estación {estacion_aleatoria}',
    labels={'Hora': 'Hora del día', 'Consumo_Wh': 'Consumo (Wh)'},
)

# Mostrar el gráfico
fig.show()





energia_solar = pd.read_excel('GeneracionHorariaFVRomaFebrero.xlsx')
energia_solar.info()


# Carga de datos
energia_solar = pd.read_excel('GeneracionHorariaFVRomaFebrero.xlsx')
df = pd.read_csv('dimensiones_mes1.csv')

# Cálculo del área de paneles solares para cada estación
area_slot = 0.566 * 1.1
df['area_paneles'] = df['slots'] * area_slot

# Crear un DataFrame con combinaciones de estaciones y horas
combined = pd.merge(
    energia_solar.assign(key=1),  # Añadimos una clave común para el cruce
    df.assign(key=1),
    on='key'
).drop('key', axis=1)

# Calcular la energía producida por cada estación
combined['energia_estacion_kWh'] = (
    combined['Generacion (kWh/m2)'] * combined['area_paneles']
)

# Agrupar por día y hora si es necesario
combined['Fecha'] = combined['Fecha_hora'].dt.date
combined['Hora'] = combined['Fecha_hora'].dt.hour

# Mostramos el resultado por día, hora y estación
energia_por_estacion = combined[['Fecha', 'Hora', 'estacion', 'energia_estacion_kWh']]

energia_por_estacion






# Calcular la producción media por hora y estación
produccion_media = energia_por_estacion.groupby(['Hora', 'estacion'])['energia_estacion_kWh'].mean().reset_index()

# Renombrar la columna para mayor claridad
produccion_media.rename(columns={'energia_estacion_kWh': 'produccion_media_kWh'}, inplace=True)
output_file = 'produccion_hora_estacion.csv'
produccion_media.to_csv(output_file, index=True)
# Mostrar un resumen de los datos
produccion_media


df_consumo = pd.read_csv('consumo_hora_estacion.csv')
produccion_media = pd.read_csv('produccion_hora_estacion.csv')
# Convertir la producción media a Wh
produccion_media['produccion_media_Wh'] = produccion_media['produccion_media_kWh'] * 1000

# Seleccionar una estación al azar
estacion_aleatoria = random.choice(consumo_hora_estacion.index)

# Preparar los datos de consumo para el gráfico
df_consumo = consumo_hora_estacion.loc[estacion_aleatoria].reset_index()
df_consumo.columns = ['Hora', 'Consumo_Wh']

# Filtrar los datos de producción para la estación seleccionada
df_produccion = produccion_media[produccion_media['estacion'] == estacion_aleatoria][['Hora', 'produccion_media_Wh']]

# Unir los datos de consumo y producción para facilitar el gráfico
df_grafico = df_consumo.merge(df_produccion, on='Hora', how='left')

# Crear el gráfico
fig = px.bar(
    df_grafico,
    x='Hora',
    y='Consumo_Wh',
    title=f'Consumo y producción promedio por hora - Estación {estacion_aleatoria}',
    labels={'Hora': 'Hora del día', 'Consumo_Wh': 'Consumo (Wh)', 'produccion_media_Wh': 'Producción (Wh)'},
)

# Añadir la línea de producción
fig.add_scatter(
    x=df_grafico['Hora'],
    y=df_grafico['produccion_media_Wh'],
    mode='lines+markers',
    name='Producción (Wh)',
    line=dict(color='orange')
)

# Mostrar el gráfico
fig.show()


df_consumo = pd.read_csv('consumo_hora_estacion.csv')
produccion_media = pd.read_csv('produccion_hora_estacion.csv')
# Convertir la producción media a Wh
produccion_media['produccion_media_Wh'] = produccion_media['produccion_media_kWh'] * 1000

# Seleccionar 10 estaciones al azar
estaciones_aleatorias = random.sample(list(consumo_hora_estacion.index), 10)

# Iterar sobre las estaciones seleccionadas
for estacion in estaciones_aleatorias:
    # Preparar los datos de consumo para el gráfico
    df_consumo = consumo_hora_estacion.loc[estacion].reset_index()
    df_consumo.columns = ['Hora', 'Consumo_Wh']

    # Filtrar los datos de producción para la estación seleccionada
    df_produccion = produccion_media[produccion_media['estacion'] == estacion][['Hora', 'produccion_media_Wh']]

    # Unir los datos de consumo y producción para facilitar el gráfico
    df_grafico = df_consumo.merge(df_produccion, on='Hora', how='left')

    # Crear el gráfico
    fig = px.bar(
        df_grafico,
        x='Hora',
        y='Consumo_Wh',
        title=f'Consumo y producción promedio por hora - Estación {estacion}',
        labels={'Hora': 'Hora del día', 'Consumo_Wh': 'Consumo (Wh)', 'produccion_media_Wh': 'Producción (Wh)'},
    )

    # Añadir la línea de producción
    fig.add_scatter(
        x=df_grafico['Hora'],
        y=df_grafico['produccion_media_Wh'],
        mode='lines+markers',
        name='Producción (Wh)',
        line=dict(color='orange')
    )

    # Mostrar el gráfico
    fig.show()
print(f"Producción media diaria de la red de paneles solares: {produccion_media['produccion_media_Wh'].sum()} Wh")






energia_consumida_media = 26253.01 #Wh
energia_producida_media = 183678.63 #Wh
energia_producida_objetivo = 35000 #Wh
factor_ajuste = energia_producida_objetivo/energia_producida_media
# Leer el archivo CSV
produccion_media = pd.read_csv('produccion_hora_estacion.csv')

# Añadir una nueva columna ajustada
produccion_media['produccion_ajustada'] = produccion_media['produccion_media_kWh']*factor_ajuste

produccion_media.to_csv('produccion_hora_estacion.csv', index=True)
# Mostrar el resultado
produccion_media.head()


df_consumo = pd.read_csv('consumo_hora_estacion.csv')
produccion_media = pd.read_csv('produccion_hora_estacion.csv')
# Convertir la producción media a Wh
produccion_media['produccion_media_Wh'] = produccion_media['produccion_ajustada'] * 1000

# Seleccionar 10 estaciones al azar
estaciones_aleatorias = random.sample(list(consumo_hora_estacion.index), 10)

# Iterar sobre las estaciones seleccionadas
for estacion in estaciones_aleatorias:
    # Preparar los datos de consumo para el gráfico
    df_consumo = consumo_hora_estacion.loc[estacion].reset_index()
    df_consumo.columns = ['Hora', 'Consumo_Wh']

    # Filtrar los datos de producción para la estación seleccionada
    df_produccion = produccion_media[produccion_media['estacion'] == estacion][['Hora', 'produccion_media_Wh']]

    # Unir los datos de consumo y producción para facilitar el gráfico
    df_grafico = df_consumo.merge(df_produccion, on='Hora', how='left')

    # Crear el gráfico
    fig = px.bar(
        df_grafico,
        x='Hora',
        y='Consumo_Wh',
        title=f'Consumo y producción promedio por hora - Estación {estacion}',
        labels={'Hora': 'Hora del día', 'Consumo_Wh': 'Consumo (Wh)', 'produccion_media_Wh': 'Producción (Wh)'},
    )

    # Añadir la línea de producción
    fig.add_scatter(
        x=df_grafico['Hora'],
        y=df_grafico['produccion_media_Wh'],
        mode='lines+markers',
        name='Producción (Wh)',
        line=dict(color='orange')
    )

    # Mostrar el gráfico
    fig.show()


# Iterar sobre las estaciones seleccionadas
for estacion in estaciones_aleatorias:
    # Preparar los datos de consumo para el gráfico
    df_consumo = consumo_hora_estacion.loc[estacion].reset_index()
    df_consumo.columns = ['Hora', 'Consumo_Wh']

    # Filtrar los datos de producción para la estación seleccionada
    df_produccion = produccion_media[produccion_media['estacion'] == estacion][['Hora', 'produccion_media_Wh']]

    # Unir los datos de consumo y producción para facilitar el cálculo
    df_grafico = df_consumo.merge(df_produccion, on='Hora', how='left')

    # Calcular la energía sobrante
    df_grafico['Energia_sobrante_Wh'] = df_grafico['produccion_media_Wh'] - df_grafico['Consumo_Wh']

    # Reemplazar valores negativos por 0 (opcional, si no quieres valores negativos de energía sobrante)
    df_grafico['Energia_sobrante_Wh'] = df_grafico['Energia_sobrante_Wh'].clip(lower=0)

    # Crear el gráfico
    fig = px.bar(
        df_grafico,
        x='Hora',
        y='Consumo_Wh',
        title=f'Consumo, producción y energía sobrante por hora - Estación {estacion}',
        labels={
            'Hora': 'Hora del día',
            'Consumo_Wh': 'Consumo (Wh)',
            'produccion_media_Wh': 'Producción (Wh)',
            'Energia_sobrante_Wh': 'Energía sobrante (Wh)'
        },
    )

    # Añadir las líneas de producción y energía sobrante
    fig.add_scatter(
        x=df_grafico['Hora'],
        y=df_grafico['produccion_media_Wh'],
        mode='lines+markers',
        name='Producción (Wh)',
        line=dict(color='orange')
    )

    fig.add_scatter(
        x=df_grafico['Hora'],
        y=df_grafico['Energia_sobrante_Wh'],
        mode='lines+markers',
        name='Energía sobrante (Wh)',
        line=dict(color='green')
    )

    # Mostrar el gráfico
    fig.show()



